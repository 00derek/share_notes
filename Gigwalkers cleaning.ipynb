{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Cleaning up 20180109.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "from pandas.io.json import json_normalize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rs = []\n",
    "df = pd.DataFrame()\n",
    "result_df = []\n",
    "# open the csv file\n",
    "with open('gigwalkers_2018.csv') as fh:\n",
    "    rows = csv.reader(fh, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "    header = next(rows)\n",
    "    for i, row in enumerate(rows):\n",
    "        # print row\n",
    "        # print len(row)\n",
    "        # last few columns are json structure data\n",
    "        js= ','.join(row[6:])\n",
    "        js = js.replace(\"\\\\\\\\\", \"\\\\\")\n",
    "        # print json.loads(js)\n",
    "        \n",
    "        rec = (row[0], row[1], row[2], row[3], row[4], row[5], json.loads(js))\n",
    "        sr = pd.Series(data=rec[0:-1])\n",
    "        sr= sr.append(json_normalize(rec[-1]).transpose())\n",
    "        df_rec = sr.transpose()\n",
    "        # print df_rec\n",
    "        # df_rec will be a datafram row\n",
    "        df = df.append(df_rec)\n",
    "        if (i+1)%1000 == 0:\n",
    "            # saving every 1000 rec. to a pickle file\n",
    "            df.to_pickle('temp/temp{}.pkl'.format(i+1))\n",
    "            # reset df to empty\n",
    "            df = pd.DataFrame()\n",
    "            # print i\n",
    "            # extra steps, not really need\n",
    "            # result_df.append(df)\n",
    "    if len(df):\n",
    "        df.to_pickle('temp/temp{}.pkl'.format('_last'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loading from all files\n",
    "arr = os.listdir('temp/')\n",
    "l = [pd.read_pickle('temp/'+pkl) for pkl in arr]\n",
    "df = pd.DataFrame()\n",
    "df = pd.concat(l)\n",
    "\n",
    "# saving to one pickle file\n",
    "df.to_pickle('gigwalkers_2018.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('gigwalkers_2018.pkl')\n",
    "# dropping existing index, coz it's all 0\n",
    "df = df.reset_index(drop=True)\n",
    "# rename the column names \n",
    "df.rename(columns={0:'agent_id', 1:'agent_salt', 2:'agent_saltedPasswordHash', 3:'email', 4: 'time_created',5:'reputation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cleaning string None values to be np.NaN \n",
    "df.replace('none', np.NaN, inplace=True)\n",
    "df.replace('N/A', np.NaN, inplace=True)\n",
    "\n",
    "# cleaning Yes/No values\n",
    "df.replace('Yes', True, inplace=True)\n",
    "df.replace('yes', True, inplace=True)\n",
    "df.replace('no', False, inplace=True)\n",
    "df.replace('False', False, inplace=True)\n",
    "df.replace('false', False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['reputation'] = df['reputation'].apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean location_time_updated, cannot use int because there's nan data\n",
    "# df['location_time_updated']= df['location_time_updated'].apply(float)\n",
    "df['location_time_updated'] = pd.to_datetime(df.location_time_updated, unit='s')\n",
    "df['location_time_updated'].replace(np.NaN, None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean lat, \n",
    "# df['lat'].apply(float) might fail, but it's a good idea to run first to know what data look like\n",
    "# mask for lat has some weird strin\n",
    "# mask = df['lat'] == u'??????????'\n",
    "# mask = df['lat'].isnull()\n",
    "df['lat'] = df['lat'].str.replace(',','.')\n",
    "df['long'] = df['long'].str.replace(',','.')\n",
    "df.lat = pd.to_numeric(df['lat'], errors='coerce')\n",
    "\n",
    "# clean long ?1.4831493, ?0.7722991, ?1.1991791, ?111.8050423\n",
    "# mask = df['long'] == '?111.8050423'\n",
    "# mask = df['long'] == '????????????'\n",
    "# mask = df['long'] == '???????'\n",
    "# mask = df['long'] == '?-?????????'\n",
    "\n",
    "# df.loc[mask, 'long'] = np.NaN\n",
    "# df['long'].apply(float)\n",
    "\n",
    "df.long = pd.to_numeric(df['long'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cleaning gender\n",
    "df.loc[df['gender'] == 'male', 'gender'] = 'Male'\n",
    "df.loc[df['gender'] == 'female', 'gender'] = 'Female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transform birthday\n",
    "df['birthday'] = pd.to_datetime(df.birthday, unit='s')\n",
    "df['birthday'].replace(np.NaN, None, inplace=True)\n",
    "# transform time_creaeted\n",
    "df['time_created'] = pd.to_datetime(df.time_created, unit='s')\n",
    "df['time_created'].replace(np.NaN, None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean up `agent_avatar`\n",
    "df['agent_avatar'].replace(False, np.NaN, inplace=True)\n",
    "df['agent_avatar'].replace('[object Object]', np.NaN, inplace=True)\n",
    "\n",
    "df.loc[df['agent_avatar'].notna(), 'agent_avatar'] = df.loc[df['agent_avatar'].notna(), 'agent_avatar'].apply(lambda x: x if '.jpg' in x else x+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean up facebook_id\n",
    "df['facebook_id'].replace(False, np.NaN, inplace=True)\n",
    "df['facebook_id'].replace('0', np.NaN, inplace=True)\n",
    "df.facebook_id = pd.to_numeric(df['facebook_id'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# change min_payout and rating to numeric value\n",
    "df.min_payout = pd.to_numeric(df['min_payout'], errors='coerce')\n",
    "df.rating = pd.to_numeric(df['rating'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean profile_picture_id\n",
    "df['profile_picture_id'] = df['profile_picture_id'].replace(False, None)\n",
    "df.loc[(df['profile_picture_id'] == False),'profile_picture_id'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these are varchar2 should not be stamped as 'False',\n",
    "df['udid'] = df['udid'].replace(False, np.NaN)\n",
    "df['device_type'] = df['device_type'].replace(False, np.NaN)\n",
    "df['device_os'] = df['device_os'].replace(False, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296527 entries, 0 to 1296526\n",
      "Data columns (total 41 columns):\n",
      "agent_id                          1296527 non-null object\n",
      "agent_salt                        1296527 non-null object\n",
      "agent_saltedPasswordHash          1296527 non-null object\n",
      "email                             1296527 non-null object\n",
      "time_created                      1296527 non-null datetime64[ns]\n",
      "reputation                        1296527 non-null float64\n",
      "APIHash                           1 non-null object\n",
      "agent_avatar                      122313 non-null object\n",
      "agent_skills                      19353 non-null object\n",
      "bio                               106779 non-null object\n",
      "birthday                          1296527 non-null datetime64[ns]\n",
      "current_city_location_id          1296523 non-null object\n",
      "device_os                         1296527 non-null object\n",
      "device_type                       1296527 non-null object\n",
      "education_level                   1296527 non-null object\n",
      "email_address                     1296525 non-null object\n",
      "facebook_access_token             1793 non-null object\n",
      "facebook_id                       1296527 non-null object\n",
      "first_name                        1296103 non-null object\n",
      "gender                            1295967 non-null object\n",
      "last_name                         1295908 non-null object\n",
      "last_place_employed_JSON          1296525 non-null object\n",
      "lat                               1279977 non-null float64\n",
      "location_time_updated             1296527 non-null datetime64[ns]\n",
      "long                              1279960 non-null float64\n",
      "metro_area_location_id            1296527 non-null object\n",
      "min_payout                        7611 non-null float64\n",
      "occupation                        1282261 non-null object\n",
      "password                          2 non-null object\n",
      "paypal_email_address              1296527 non-null object\n",
      "phone_number                      1 non-null object\n",
      "profile_picture_id                1088684 non-null object\n",
      "push_notification_device_token    1296527 non-null object\n",
      "rating                            1296526 non-null float64\n",
      "skills_hotel                      1296523 non-null object\n",
      "skills_photography                1296523 non-null object\n",
      "skills_real_estate                1296523 non-null object\n",
      "skills_restaurant                 1296523 non-null object\n",
      "skills_retail                     1296523 non-null object\n",
      "skills_writing                    1296523 non-null object\n",
      "udid                              1115733 non-null object\n",
      "dtypes: datetime64[ns](3), float64(5), object(33)\n",
      "memory usage: 405.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up the length\n",
    "df['agent_id'] = df['agent_id'].astype(str).apply(lambda x: x[:200] if x else x)\n",
    "#df['occupation'] = df['occupation'].astype(str).apply(lambda x: x[:150] if x else x)\n",
    "df['education_level'] = df['education_level'].astype(str).apply(lambda x: x[0:150] if x else x)\n",
    "df['facebook_id'] = df['facebook_id'].astype(str).apply(lambda x: x[:64] if x else x)\n",
    "df['device_type'] = df['device_type'].astype(str).apply(lambda x: x[:50] if x else x)\n",
    "df['device_os'] = df['device_os'].astype(str).apply(lambda x: x[:50] if x else x)\n",
    "df['push_notification_device_token'] = df['push_notification_device_token'].astype(str).apply(lambda x: x[:200] if x else x)\n",
    "df['paypal_email_address'] = df['paypal_email_address'].astype(str).apply(lambda x: x[:150] if x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_pickle('gigwalkers_2018_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ignoring columns: \n",
    "# current_city_location_id, in 3.0 wrongly designed as integer, where data is mostly string\n",
    "# metro_area_location_id, in 3.0 wrongly designed as integer, where data is mostly string\n",
    "# email_address, 9 different, we can ignore\n",
    "# agent_skills, looks like a dictionary\n",
    "# api_hash, not defined in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3.0 dataframe and comparing with 2.0 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('gigwalkers_2018_cleaned.pkl')\n",
    "df3 = pd.read_csv('3.0agents_data.csv')\n",
    "df_merge=pd.merge(df,df3,on=['agent_id'],how=\"outer\",indicator=True)\n",
    "need_import = df_merge[df_merge['_merge'] == 'left_only']\n",
    "need_import = need_import.where((pd.notnull(need_import)), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import to 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import, so obviously these code need to be run under gigwalk app\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy_utils.types.phone_number import PhoneNumber\n",
    "from gigwalk_api_app.customers.models import Customer\n",
    "from gigwalk_api_app.customer_profile.models import CustomerProfile\n",
    "from datetime import datetime\n",
    "from gigwalk_api_app.tz_world.models import TZWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "df = pd.read_pickle('gigwalkers_2018_cleaned.pkl')\n",
    "df3 = pd.read_csv('3.0agents_data.csv')\n",
    "df_merge=pd.merge(df,df3,on=['agent_id'],how=\"outer\",indicator=True)\n",
    "need_import = df_merge[df_merge['_merge'] == 'left_only']\n",
    "need_import = need_import.where((pd.notnull(need_import)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lp = LocationProxy(app.config)\n",
    "def map_avatar(avatar):\n",
    "    # sometimes agent_avatar is False so we have to replace that with the default image\n",
    "    if not avatar:\n",
    "        return 'http://www.gigwalk.com/img/default-user-image.gif'\n",
    "    else:\n",
    "        return 'https://s3-us-west-1.amazonaws.com/gigwalk-profile-photos/{}'.format(avatar)\n",
    "\n",
    "def create_customer(agent):\n",
    "    email = agent.get('email')\n",
    "    customer = Customer.get_by_email(email)\n",
    "    # Create new user if does not exists\n",
    "    if customer:\n",
    "        print customer.id, customer.email, customer.organization_id\n",
    "    \n",
    "    customer = Customer()\n",
    "    customer.first_name = agent.get('first_name')\n",
    "    customer.last_name = agent.get('last_name')\n",
    "    customer._password = agent.get('agent_saltedPasswordHash').encode('utf8')\n",
    "    customer._salt = agent.get('agent_salt')\n",
    "    customer.photo_url = map_avatar(agent.get('agent_avatar'))\n",
    "    customer.customer_status = 'ACTIVE'\n",
    "    customer.email = agent.get('email')\n",
    "    customer.date_created = agent.get('agent_create_timestamp')\n",
    "    customer.organization_id = 5\n",
    "    customer.role = 'WORKER'\n",
    "    customer.home_latitude = agent.get('lat')\n",
    "    customer.home_longitude = agent.get('long')\n",
    "    customer.date_updated = agent.get('location_time_updated')\n",
    "    \n",
    "          \n",
    "    # if not customer.profile:\n",
    "    profile_keys = [u'rating', u'device_type', u'skills_hotel', u'agent_skills', u'profile_picture_id', u'education_level', u'push_notification_device_token', u'occupation', u'skills_writing', u'paypal_email_address', u'skills_real_estate', u'facebook_id', u'min_payout', u'phone_number', u'bio', u'skills_retail', u'last_place_employed_JSON', u'facebook_access_token', u'skills_restaurant', u'birthday', u'device_os', u'skills_photography', u'udid', u'gender', u'APIHash', 'reputation', u'agent_avatar', 'agent_id']\n",
    "    customer.profile = CustomerProfile()\n",
    "    customer.profile.date_created = datetime.now()    \n",
    "    for k, v in agent.items():\n",
    "        if k in profile_keys:\n",
    "            setattr(customer.profile, k, v)\n",
    "\n",
    "    # set tzid and home address\n",
    "    if customer.home_latitude and customer.home_longitude:\n",
    "        try:\n",
    "            print \"tzid\"\n",
    "            # customer.tzid = TZWorld.tzid_from_coordinates(customer.home_longitude, customer.home_latitude)\n",
    "        except Exception as e:\n",
    "            # Probably a glitch, just ignore and continue\n",
    "            print(\"Error {} in calculating timezone while importing {}\".format(e, customer.email))\n",
    "        try:\n",
    "            loc = lp.reverse_geocode(customer.home_latitude, customer.home_longitude)\n",
    "        except Exception as e:\n",
    "            # Probably some geocoding glitch, just ignore and go to the next customer\n",
    "            print(\"Geocoding error {} while importing {}\".format(e, customer.email))\n",
    "\n",
    "        if loc:\n",
    "            acs = loc.raw.get('address_components')\n",
    "            street_number = None\n",
    "            route = None\n",
    "            for ac in acs:\n",
    "                loc_type = str(ac.get('types')[0])\n",
    "                if loc_type == 'subpremise':\n",
    "                    customer.address_line_2 = ac.get('short_name')\n",
    "                elif loc_type == 'street_number':\n",
    "                    street_number = ac.get('short_name')\n",
    "                elif loc_type in ['street_address', 'premise']:\n",
    "                    customer.address_line_1 = ac.get('short_name')\n",
    "                elif loc_type == 'route':\n",
    "                    route = ac.get('short_name')\n",
    "                elif loc_type == 'postal_code':\n",
    "                    customer.postal_code = ac.get('short_name')\n",
    "                elif loc_type == 'locality':\n",
    "                    customer.city = ac.get('short_name')\n",
    "                elif loc_type == 'administrative_area_level_1':\n",
    "                    customer.state = ac.get('short_name')\n",
    "                elif loc_type == 'country' and customer.profile.phone_number:\n",
    "                    country = ac.get('short_name')\n",
    "                    customer.phonenumber = PhoneNumber(customer.profile.phone_number, country)\n",
    "            if not customer.address_line_1 and route:\n",
    "                customer.address_line_1 = street_number + ' ' + route if street_number else route\n",
    "          \n",
    "    customer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for index, row in need_import.head(1200).iterrows():\n",
    "    create_customer(dict(row))\n",
    "elapsed_time = time.time() - start_time\n",
    "print \"total time spent :{} sec\".format(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this is using gmaps API to do geocoding, should NOT use it for 1.2M gigwalkers\n",
    "# let's checkout the following link for state, county search, or maybe a radius search could work\n",
    "# https://github.com/thampiman/reverse-geocoder \n",
    "\n",
    "def find_zipcode(lat_long):\n",
    "    lat, longti = lat_long.split(',')\n",
    "    reverse_geocode_result = gmaps.reverse_geocode((lat, longti))\n",
    "    if reverse_geocode_result:\n",
    "        components = reverse_geocode_result[0]['address_components']\n",
    "        for comp in components:\n",
    "            if 'postal_code' in comp['types']:\n",
    "                return int(comp['short_name'])\n",
    "    else:\n",
    "        return None\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
