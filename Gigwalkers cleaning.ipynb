{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dumping 2.0 data\n",
    "have to break it 2 parts because mysql killed the long process\n",
    "- Part 1\n",
    "```\n",
    "mysql -h gs-read-2016-3-24-1.cpkpnksgl3uc.us-west-1.rds.amazonaws.com -u inka -pcharleebear gigspoon -e \"select concat(agent_id,',', agent_salt, ',',agent_saltedPasswordHash, ',',agent_email_address,',' ,agent_create_timestamp,',',agent_reputation, ',',agent_structured_data) from agent_accounts where agent_account_state = 'APPROVED' order by agent_id limit 700000\" > gigwalkers_20180111.csv\n",
    "```\n",
    "\n",
    "- Part 2\n",
    "```\n",
    "mysql -h gs-read-2016-3-24-1.cpkpnksgl3uc.us-west-1.rds.amazonaws.com -u inka -pcharleebear gigspoon -e \"select concat(agent_id,',', agent_salt, ',',agent_saltedPasswordHash, ',',agent_email_address,',' ,agent_create_timestamp,',',agent_reputation, ',',agent_structured_data) from agent_accounts where agent_account_state = 'APPROVED' order by agent_id limit 700000, 1296000\" > gigwalkers_20180111_2.csv\n",
    "```\n",
    "- copy(scp) it to local machine & remove first line of part2 data header\n",
    "\n",
    "- Concat them\n",
    "```\n",
    "cat gigwalkers_20180111.csv gigwalkers_20180111_2.csv > gigwalkers_2018.csv\n",
    "```\n",
    "\n",
    "- getting 3.0 data, change sql as needed\n",
    "```\n",
    "psql -U derek -d gw_apps_1 -p 5432 -h new-prod.cgxxy7nmhwzi.us-east-1.rds.amazonaws.com -c                             \n",
    "\"Copy (SELECT agent_id from customer_profile where agent_id is not NULL) To STDOUT With CSV HEADER DELIMITER ',';\" > 3.0agents_data.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Cleaning up 20180109.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "from pandas.io.json import json_normalize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rs = []\n",
    "df = pd.DataFrame()\n",
    "result_df = []\n",
    "# open the csv file\n",
    "with open('gigwalkers_2018.csv') as fh:\n",
    "    rows = csv.reader(fh, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "    header = next(rows)\n",
    "    for i, row in enumerate(rows):\n",
    "        # print row\n",
    "        # print len(row)\n",
    "        # last few columns are json structure data\n",
    "        js= ','.join(row[6:])\n",
    "        js = js.replace(\"\\\\\\\\\", \"\\\\\")\n",
    "        # print json.loads(js)\n",
    "        \n",
    "        rec = (row[0], row[1], row[2], row[3], row[4], row[5], json.loads(js))\n",
    "        sr = pd.Series(data=rec[0:-1])\n",
    "        sr= sr.append(json_normalize(rec[-1]).transpose())\n",
    "        df_rec = sr.transpose()\n",
    "        # print df_rec\n",
    "        # df_rec will be a datafram row\n",
    "        df = df.append(df_rec)\n",
    "        if (i+1)%1000 == 0:\n",
    "            # saving every 1000 rec. to a pickle file\n",
    "            df.to_pickle('temp/temp{}.pkl'.format(i+1))\n",
    "            # reset df to empty\n",
    "            df = pd.DataFrame()\n",
    "            # print i\n",
    "            # extra steps, not really need\n",
    "            # result_df.append(df)\n",
    "    if len(df):\n",
    "        df.to_pickle('temp/temp{}.pkl'.format('_last'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loading from all files\n",
    "arr = os.listdir('temp/')\n",
    "l = [pd.read_pickle('temp/'+pkl) for pkl in arr]\n",
    "df = pd.DataFrame()\n",
    "df = pd.concat(l)\n",
    "\n",
    "# saving to one pickle file\n",
    "df.to_pickle('gigwalkers_2018.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('gigwalkers_2018.pkl')\n",
    "# dropping existing index, coz it's all 0\n",
    "df = df.reset_index(drop=True)\n",
    "# rename the column names \n",
    "df.rename(columns={0:'agent_id', 1:'agent_salt', 2:'agent_saltedPasswordHash', 3:'email', 4: 'time_creaeted',5:'reputation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cleaning None values\n",
    "df.replace('none', np.NaN, inplace=True)\n",
    "df.replace('N/A', np.NaN, inplace=True)\n",
    "\n",
    "# cleaning Yes/No values\n",
    "df.replace('Yes', True, inplace=True)\n",
    "df.replace('yes', True, inplace=True)\n",
    "df.replace('no', False, inplace=True)\n",
    "df.replace('False', False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['reputation'] = df['reputation'].apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean location_time_updated, cannot use int because there's nan data\n",
    "# df['location_time_updated']= df['location_time_updated'].apply(float)\n",
    "df['location_time_updated'] = pd.to_datetime(df.location_time_updated, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean lat, \n",
    "# df['lat'].apply(float) might fail, but it's a good idea to run first to know what data look like\n",
    "# mask for lat has some weird strin\n",
    "# mask = df['lat'] == u'??????????'\n",
    "# mask = df['lat'].isnull()\n",
    "df['lat'] = df['lat'].str.replace(',','.')\n",
    "df['long'] = df['long'].str.replace(',','.')\n",
    "df.lat = pd.to_numeric(df['lat'], errors='coerce')\n",
    "\n",
    "# clean long ?1.4831493, ?0.7722991, ?1.1991791, ?111.8050423\n",
    "# mask = df['long'] == '?111.8050423'\n",
    "# mask = df['long'] == '????????????'\n",
    "# mask = df['long'] == '???????'\n",
    "# mask = df['long'] == '?-?????????'\n",
    "\n",
    "# df.loc[mask, 'long'] = np.NaN\n",
    "# df['long'].apply(float)\n",
    "\n",
    "df.long = pd.to_numeric(df['long'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cleaning gender\n",
    "df.loc[df['gender'] == 'male', 'gender'] = 'Male'\n",
    "df.loc[df['gender'] == 'female', 'gender'] = 'Female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transform birthday\n",
    "df['birthday'] = pd.to_datetime(df.birthday, unit='s')\n",
    "# transform time_creaeted\n",
    "df['time_creaeted'] = pd.to_datetime(df.time_creaeted, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean up `agent_avatar`\n",
    "df['agent_avatar'].replace(False, np.NaN, inplace=True)\n",
    "df['agent_avatar'].replace('[object Object]', np.NaN, inplace=True)\n",
    "\n",
    "df.loc[df['agent_avatar'].notna(), 'agent_avatar'] = df.loc[df['agent_avatar'].notna(), 'agent_avatar'].apply(lambda x: x if '.jpg' in x else x+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean up facebook_id\n",
    "df['facebook_id'].replace(False, np.NaN, inplace=True)\n",
    "df['facebook_id'].replace('0', np.NaN, inplace=True)\n",
    "df.facebook_id = pd.to_numeric(df['facebook_id'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# change min_payout and rating to numeric value\n",
    "df.min_payout = pd.to_numeric(df['min_payout'], errors='coerce')\n",
    "df.rating = pd.to_numeric(df['rating'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean profile_picture_id\n",
    "df['profile_picture_id'] = df['profile_picture_id'].replace(False, None)\n",
    "df.loc[(df['profile_picture_id'] == False),'profile_picture_id'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these are varchar2 should not be stamped as 'False'\n",
    "df['udid'] = df['udid'].replace(False, np.NaN)\n",
    "df['device_type'] = df['device_type'].replace(False, np.NaN)\n",
    "df['device_os'] = df['device_os'].replace(False, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_pickle('gigwalkers_2018_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ignoring columns: \n",
    "# current_city_location_id, in 3.0 wrongly designed as integer, where data is mostly string\n",
    "# metro_area_location_id, in 3.0 wrongly designed as integer, where data is mostly string\n",
    "# email_address, 9 different, we can ignore\n",
    "# agent_skills, looks like a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3.0 dataframe and comparing with 2.0 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('gigwalkers_2018_cleaned.pkl')\n",
    "df3 = pd.read_csv('3.0agents_data.csv')\n",
    "df_merge=pd.merge(df,df3,on=['agent_id'],how=\"outer\",indicator=True)\n",
    "need_import = df_merge[df_merge['_merge'] == 'left_only']\n",
    "need_import = need_import.where((pd.notnull(need_import)), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import to 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import, so obviously these code need to be run under gigwalk app\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy_utils.types.phone_number import PhoneNumber\n",
    "from gigwalk_api_app.customers.models import Customer\n",
    "from gigwalk_api_app.customer_profile.models import CustomerProfile\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "df = pd.read_pickle('gigwalkers_2018_cleaned.pkl')\n",
    "df3 = pd.read_csv('3.0agents_data.csv')\n",
    "df_merge=pd.merge(df,df3,on=['agent_id'],how=\"outer\",indicator=True)\n",
    "need_import = df_merge[df_merge['_merge'] == 'left_only']\n",
    "need_import = need_import.where((pd.notnull(need_import)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lp = LocationProxy(app.config)\n",
    "def map_avatar(avatar):\n",
    "    # sometimes agent_avatar is False so we have to replace that with the default image\n",
    "    if not avatar:\n",
    "        return 'http://www.gigwalk.com/img/default-user-image.gif'\n",
    "    else:\n",
    "        return 'https://s3-us-west-1.amazonaws.com/gigwalk-profile-photos/{}'.format(avatar)\n",
    "\n",
    "def create_customer(agent):\n",
    "    email = agent.get('email')\n",
    "    customer = Customer.get_by_email(email)\n",
    "    # Create new user if does not exists\n",
    "    if customer:\n",
    "        return\n",
    "    \n",
    "    customer = Customer()\n",
    "    customer.first_name = agent.get('first_name')\n",
    "    customer.last_name = agent.get('last_name')\n",
    "    customer._password = agent.get('agent_saltedPasswordHash').encode('utf8')\n",
    "    customer._salt = agent.get('agent_salt')\n",
    "    customer.photo_url = map_avatar(agent.get('agent_avatar'))\n",
    "    customer.customer_status = 'ACTIVE'\n",
    "    customer.email = agent.get('email')\n",
    "    customer.date_created = agent.get('agent_create_timestamp')\n",
    "    customer.organization_id = 5\n",
    "    customer.role = 'WORKER'\n",
    "    customer.home_latitude = agent.get('lat')\n",
    "    customer.home_longitude = agent.get('long')\n",
    "    customer.date_updated = agent.get('location_time_updated')\n",
    "    \n",
    "          \n",
    "    # if not customer.profile:\n",
    "    profile_keys = [u'rating', u'device_type', u'skills_hotel', u'agent_skills', u'profile_picture_id', u'education_level', u'push_notification_device_token', u'occupation', u'skills_writing', u'paypal_email_address', u'skills_real_estate', u'facebook_id', u'min_payout', u'phone_number', u'bio', u'skills_retail', u'last_place_employed_JSON', u'facebook_access_token', u'skills_restaurant', u'birthday', u'device_os', u'skills_photography', u'udid', u'gender', u'APIHash', 'reputation', u'agent_avatar', 'agent_id']\n",
    "    customer.profile = CustomerProfile()\n",
    "    customer.profile.date_created = datetime.now()    \n",
    "    for k, v in agent.items():\n",
    "        if k in profile_keys:\n",
    "            setattr(customer.profile, k, v)\n",
    "\n",
    "    # set tzid and home address\n",
    "    if customer.home_latitude and customer.home_longitude:\n",
    "        try:\n",
    "        \tprint \"tzid\"\n",
    "            # customer.tzid = TZWorld.tzid_from_coordinates(customer.home_longitude, customer.home_latitude)\n",
    "        except Exception as e:\n",
    "            # Probably a glitch, just ignore and continue\n",
    "            print(\"Error {} in calculating timezone while importing {}\".format(e, customer.email))\n",
    "        try:\n",
    "            loc = lp.reverse_geocode(customer.home_latitude, customer.home_longitude)\n",
    "        except Exception as e:\n",
    "            # Probably some geocoding glitch, just ignore and go to the next customer\n",
    "            print(\"Geocoding error {} while importing {}\".format(e, customer.email))\n",
    "\n",
    "        if loc:\n",
    "            acs = loc.raw.get('address_components')\n",
    "            street_number = None\n",
    "            route = None\n",
    "            for ac in acs:\n",
    "                loc_type = str(ac.get('types')[0])\n",
    "                if loc_type == 'subpremise':\n",
    "                    customer.address_line_2 = ac.get('short_name')\n",
    "                elif loc_type == 'street_number':\n",
    "                    street_number = ac.get('short_name')\n",
    "                elif loc_type in ['street_address', 'premise']:\n",
    "                    customer.address_line_1 = ac.get('short_name')\n",
    "                elif loc_type == 'route':\n",
    "                    route = ac.get('short_name')\n",
    "                elif loc_type == 'postal_code':\n",
    "                    customer.postal_code = ac.get('short_name')\n",
    "                elif loc_type == 'locality':\n",
    "                    customer.city = ac.get('short_name')\n",
    "                elif loc_type == 'administrative_area_level_1':\n",
    "                    customer.state = ac.get('short_name')\n",
    "                elif loc_type == 'country' and customer.profile.phone_number:\n",
    "                    country = ac.get('short_name')\n",
    "                    customer.phonenumber = PhoneNumber(customer.profile.phone_number, country)\n",
    "            if not customer.address_line_1 and route:\n",
    "                customer.address_line_1 = street_number + ' ' + route if street_number else route\n",
    "          \n",
    "    customer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, row in need_import.head(3).iterrows():\n",
    "    create_customer(dict(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this is using gmaps API to do geocoding, should NOT use it for 1.2M gigwalkers\n",
    "# let's checkout the following link for state, county search, or maybe a radius search could work\n",
    "# https://github.com/thampiman/reverse-geocoder \n",
    "\n",
    "def find_zipcode(lat_long):\n",
    "    lat, longti = lat_long.split(',')\n",
    "    reverse_geocode_result = gmaps.reverse_geocode((lat, longti))\n",
    "    if reverse_geocode_result:\n",
    "        components = reverse_geocode_result[0]['address_components']\n",
    "        for comp in components:\n",
    "            if 'postal_code' in comp['types']:\n",
    "                return int(comp['short_name'])\n",
    "    else:\n",
    "        return None\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
